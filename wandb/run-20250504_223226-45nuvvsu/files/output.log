Initialized SimpleAdapter: Input Dim=512, Output Dim=256, Seq Len=1
Loading model and processor from facebook/detr-resnet-50...
config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 4.59k/4.59k [00:00<00:00, 1.55MB/s]
model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 167M/167M [00:00<00:00, 305MB/s]
[2025-05-04 22:33:00,548][timm.models._builder][INFO] - Loading pretrained weights from Hugging Face hub (timm/resnet50.a1_in1k)
model.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 102M/102M [00:00<00:00, 373MB/s]
[2025-05-04 22:33:00,948][timm.models._hub][INFO] - [timm/resnet50.a1_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.
[2025-05-04 22:33:01,070][timm.models._builder][INFO] - Missing keys (fc.weight, fc.bias) discovered while loading pretrained weights. This is expected if model is being adapted.
Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']
- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
preprocessor_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 290/290 [00:00<00:00, 173kB/s]
DETR decoder trainable
DETR prediction heads are trainable.
AdapterDetrModel initialized.
No checkpoint found, starting from scratch.
[2025-05-04 22:33:05,090][root][ERROR] - Failed to load CLIP features: [Errno 2] No such file or directory: 'data/longclip-emb/vision_features.pt'
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/hertrich/VI_project/ODCE/main.py", line 74, in main
    dataloader = get_dataloader(dataset_name=config.data.dataset_name,
  File "/home/hertrich/VI_project/ODCE/data/dataloader.py", line 191, in get_dataloader
    dataset = RefL4Dataset(
  File "/home/hertrich/VI_project/ODCE/data/dataloader.py", line 53, in __init__
    self._load_clip_features()
  File "/home/hertrich/VI_project/ODCE/data/dataloader.py", line 97, in _load_clip_features
    self.vision_features = torch.load(vision_path)
  File "/home/hertrich/.local/lib/python3.9/site-packages/torch/serialization.py", line 1425, in load
    with _open_file_like(f, "rb") as opened_file:
  File "/home/hertrich/.local/lib/python3.9/site-packages/torch/serialization.py", line 751, in _open_file_like
    return _open_file(name_or_buffer, mode)
  File "/home/hertrich/.local/lib/python3.9/site-packages/torch/serialization.py", line 732, in __init__
    super().__init__(open(name, mode))
FileNotFoundError: [Errno 2] No such file or directory: 'data/longclip-emb/vision_features.pt'

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
